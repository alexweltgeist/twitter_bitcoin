{"cells":[{"cell_type":"markdown","source":["# Tweets streaming - Consumer\nRead Stream into dataframe, add timestamp, sentiment and price, save aggregated window"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad0e3d4a-8bd9-4cae-b8eb-3b927808df2f"}}},{"cell_type":"code","source":["!pip install textblob\n!pip install pycountry\n!pip install tensorflow\n!pip install keras\n!pip install gensim"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8727cd14-9354-470c-b673-2462189e90a1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nfrom textblob import TextBlob\nimport re\nimport pycountry\nfrom datetime import datetime\nimport requests\nimport pandas as pd\nimport time\nimport tqdm"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0a80725-63a1-45cb-93ce-c32bea9e2786"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Funktions to split away the timestamp from the tweet message\n@udf\ndef split_start(text):\n  stamp = text[:-27]\n  return stamp\n@udf\ndef split_back(text):\n  stamp = text[-21:-4]     # -4 because reading it without milliseconds \n  return stamp\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"870ca57a-2ec4-4063-8abc-b9d13fbc0ef6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Additional cleaning and splitting of the incoming text\ndef preprocessing(lines):\n    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n    words = words.na.replace('', None)\n    words = words.na.drop()\n    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n    words = words.withColumn('tweet_txt', split_start('word'))\n    words = words.withColumn('stamp', split_back('word'))\n    return words\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd0eb157-1b84-4a21-99ab-41968122498f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Apply Textblob Sentiment Analysis\ndef polarity_detection(text):\n    return TextBlob(text).sentiment.polarity\ndef language_detection(text):\n    try:\n      iso_code = TextBlob(text).detect_language()\n      language = pycountry.languages.get(alpha_2=iso_code)\n      language_name = language.name\n    except:\n      language_name = 'no language detected'\n    return language_name\n# Define sentiment score\ndef getTextAnalysis(polarity):\n    pol = float(polarity)\n    if pol < 0:\n        return \"Negative\"\n    elif pol == 0:\n        return \"Neutral\"\n    else:\n        return \"Positive\"\ndef text_classification(words):\n    # polarity detection\n    polarity_detection_udf = udf(polarity_detection, StringType())\n    words = words.withColumn(\"polarity\", polarity_detection_udf(\"tweet_txt\"))\n    # language detection\n    language_detection_udf = udf(language_detection, StringType())\n    words = words.withColumn(\"language\", language_detection_udf(\"tweet_txt\"))\n    # Score sentiment definition\n    score_sentiment_udf = udf(getTextAnalysis, StringType())\n    words = words.withColumn(\"score\", score_sentiment_udf(\"polarity\"))\n    return words\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7561101-ece8-4f3a-89c8-4903e2118d5a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Create Spark session\nspark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n\n# Read the tweet data from socket\nlines = spark.readStream.format(\"socket\") \\\n        .option(\"host\", \"localhost\") \\\n        .option(\"port\", 9997) \\\n        .load()\n\n# Preprocess the data\nwords = preprocessing(lines)\n\n# Apply comulmn with text classification to define polarity and subjectivity\nwords = text_classification(words)\n\n# Filter all tweets in English\nwords = words.filter(words.language == \"English\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d84e3deb-23ed-4096-9564-803c4859336d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(words)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d575e06-5241-44ef-a063-352e884d42e5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write new data to Parquet files\nwords \\\n    .writeStream \\\n    .format(\"parquet\") \\\n    .option(\"checkpointLocation\", \"dbfs:/FileStore/checkpoint/\") \\\n    .option(\"path\", \"dbfs:/FileStore/project/\") \\\n    .start()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47c7d644-0214-4747-bc57-9311d22159b6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Read parquet files\nparqDF = spark.read.parquet(\"dbfs:/FileStore/project/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9d4cf5a-00db-458a-971e-a4e0ff59ed4b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Show all entries\nparqDF.createOrReplaceTempView(\"ParquetTable\")\nparkSQL = spark.sql(\"select * from ParquetTable\")\n#parkSQL.collect()\nparkSQL.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83881741-bfdf-485f-8849-bdb1e101b72a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#%fs rm -r dbfs:/FileStore/project/export"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bc22ebb-6181-42ae-9308-0603e507d827"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#%fs ls dbfs:/FileStore/original/tweet_sparksql/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6ac5f98-83aa-4b41-9cf1-faeb4a5a2f88"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write DataFrame data to CSV file\npath = \"dbfs:/FileStore/project/export\"\nexport_csv = parkSQL.select(\"tweet_txt\",\"score\")\n#export_csv.write.csv(path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31e720d0-1b8e-4977-b9ab-4b491ba47089"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["export_csv.write.option(\"header\",True)\\\n          .option(\"delimiter\",\";\")\\\n          .csv(path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7451ede3-692d-4fab-b310-0dae41ae4794"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["export_csv.coalesce(1).write.csv(path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64b41949-cc93-426f-9ec8-fb48aa537a1d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.csv(path)\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af3a3133-97ca-4c5b-a137-573b20ca98f9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2c44a07-fcde-4900-a0ea-e132a38b9b77"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Twitter_Project_CNN_v01","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3147761109499684}},"nbformat":4,"nbformat_minor":0}
